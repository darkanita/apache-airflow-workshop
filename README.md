# Workshop de Apache Airflow

Workshop completo de Apache Airflow con slides interactivos y ejercicios prácticos hands-on. Aprende orquestación de workflows, DAGs, operadores y mejores prácticas para data pipelines. Ideal para data engineers y desarrolladores.

## 📋 Descripción

Este workshop está diseñado para proporcionar una comprensión completa de Apache Airflow, desde conceptos básicos hasta técnicas avanzadas de orquestación de workflows. A través de presentaciones interactivas y ejercicios prácticos, los participantes aprenderán a:

- Entender los conceptos fundamentales de Apache Airflow
- Crear y gestionar DAGs (Directed Acyclic Graphs)
- Trabajar con diferentes tipos de operadores
- Implementar mejores prácticas para data pipelines
- Monitorear y debuggear workflows
- Aplicar patrones comunes en proyectos reales

## 🎯 Audiencia objetivo

- Data Engineers
- Desarrolladores Python
- DevOps Engineers
- Analistas de datos con experiencia técnica
- Cualquier profesional interesado en orquestación de workflows

## 📚 Estructura del repositorio

```
apache-airflow-workshop/
├── README.md                 # Descripción, instrucciones, índice (este archivo)
├── slides/                   # Slides individuales en formato Markdown
├── assets/                   # Imágenes y recursos visuales del workshop
└── docs/                     # Documentación adicional y guías detalladas
```

## 🚀 Instrucciones de uso

### Para participantes del workshop:

1. **Clona este repositorio:**
   ```bash
   git clone https://github.com/darkanita/apache-airflow-workshop.git
   cd apache-airflow-workshop
   ```

2. **Revisa la documentación en orden:**
   - Comienza con este README
   - Navega a `slides/` para seguir las presentaciones
   - Consulta `docs/` para información detallada
   - Utiliza `assets/` para acceder a recursos visuales

3. **Configuración del entorno:**
   - Consulta `docs/instalacion-detallada.md` para instrucciones específicas de tu sistema operativo

### Para instructores:

1. Las slides en `slides/` están organizadas secuencialmente
2. Los recursos visuales en `assets/` apoyan las presentaciones
3. La documentación en `docs/` proporciona material de referencia adicional

## 📖 Contenido del workshop

### Módulo 1: Introducción
- Qué es Apache Airflow
- Casos de uso comunes
- Arquitectura general

### Módulo 2: Conceptos básicos
- DAGs y Tasks
- Operadores
- Scheduling y dependencias

### Módulo 3: Instalación y configuración
- Instalación local
- Configuración básica
- Interface web

### Módulo 4: Primeros DAGs
- Creando tu primer DAG
- Estructura y sintaxis
- Ejercicios prácticos

### Módulo 5: Operadores
- Tipos de operadores
- Operadores más comunes
- Crear operadores personalizados

### Módulo 6: Mejores prácticas
- Patrones recomendados
- Manejo de errores
- Testing

### Módulo 7: Monitoreo y debugging
- Interface web de Airflow
- Logs y métricas
- Troubleshooting

### Módulo 8: Ejercicios prácticos
- Casos de uso reales
- Implementación hands-on

## 🛠️ Prerrequisitos

- Conocimiento básico de Python
- Familiaridad con conceptos de data pipelines
- Docker (opcional, para instalación containerizada)

## 📝 Recursos adicionales

- [Documentación oficial de Apache Airflow](https://airflow.apache.org/docs/)
- [Repositorio oficial en GitHub](https://github.com/apache/airflow)
- [Comunidad y foros](https://airflow.apache.org/community/)

## 🤝 Contribuciones

¡Las contribuciones son bienvenidas! Si encuentras errores o tienes sugerencias de mejora:

1. Abre un issue describiendo el problema o mejora
2. Fork el repositorio
3. Crea una rama para tu cambio
4. Envía un pull request

## 📄 Licencia

Este workshop está disponible bajo la licencia MIT. Ver el archivo LICENSE para más detalles.

---

**¿Listo para comenzar?** 🚀 Ve a la carpeta `slides/` y comienza con `01-introduccion.md`
